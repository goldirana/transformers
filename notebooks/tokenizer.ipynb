{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-03-11 22:53:51--  https://huggingface.co/datasets/DarwinAnim8or/the-verdict/resolve/main/the-verdict.txt\n",
      "Resolving huggingface.co (huggingface.co)... 54.192.171.40, 54.192.171.56, 54.192.171.53, ...\n",
      "Connecting to huggingface.co (huggingface.co)|54.192.171.40|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 20643 (20K) [text/plain]\n",
      "Saving to: ‘the-verdict.txt’\n",
      "\n",
      "the-verdict.txt     100%[===================>]  20.16K  --.-KB/s    in 0s      \n",
      "\n",
      "2025-03-11 22:53:51 (74.8 MB/s) - ‘the-verdict.txt’ saved [20643/20643]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "! wget https://huggingface.co/datasets/DarwinAnim8or/the-verdict/resolve/main/the-verdict.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"the-verdict.txt\", \"r\") as f:\n",
    "    text = f.read()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "result = re.split(r'([,.:;?_!\"()\\']|--|\\s)', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = [item for item in result if item.strip()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = {}\n",
    "for i, char in enumerate(set(result)):\n",
    "    vocab.update({i: char})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'fact',\n",
       " 1: 'wincing',\n",
       " 2: 'ah',\n",
       " 3: 'genius',\n",
       " 4: 'bronzes',\n",
       " 5: 'earth',\n",
       " 6: 'won',\n",
       " 7: 'made',\n",
       " 8: 'boudoir',\n",
       " 9: 'each',\n",
       " 10: 'modest',\n",
       " 11: 'manage',\n",
       " 12: 'jealousy',\n",
       " 13: 'fewer',\n",
       " 14: 'stocked',\n",
       " 15: 'cigar',\n",
       " 16: 'put',\n",
       " 17: 'grayish',\n",
       " 18: 'twenty',\n",
       " 19: 'weeks',\n",
       " 20: 'distinguished',\n",
       " 21: 'showed',\n",
       " 22: 'enlightenment',\n",
       " 23: 'swelling',\n",
       " 24: 'their',\n",
       " 25: 'something',\n",
       " 26: 'than',\n",
       " 27: 'bath-rooms',\n",
       " 28: 'forgive',\n",
       " 29: 'merely',\n",
       " 30: 'are',\n",
       " 31: 'circus-clown',\n",
       " 32: 'business',\n",
       " 33: 'three',\n",
       " 34: 'immediately',\n",
       " 35: 'found',\n",
       " 36: 'answered',\n",
       " 37: 'open',\n",
       " 38: 'exasperated',\n",
       " 39: 'managed',\n",
       " 40: 'dining-room',\n",
       " 41: 'life',\n",
       " 42: 'beaming',\n",
       " 43: 'breaking',\n",
       " 44: 'whole',\n",
       " 45: 'had',\n",
       " 46: 'mediocrity',\n",
       " 47: 'fragments',\n",
       " 48: 'Grindle',\n",
       " 49: 'villa',\n",
       " 50: 'upon',\n",
       " 51: 'Professional',\n",
       " 52: 'Usually',\n",
       " 53: 'hanging',\n",
       " 54: 'll',\n",
       " 55: 'arm',\n",
       " 56: 'laid',\n",
       " 57: 'them',\n",
       " 58: 'preliminary',\n",
       " 59: 'brought',\n",
       " 60: 'line',\n",
       " 61: 'left',\n",
       " 62: 'Rome',\n",
       " 63: 'come',\n",
       " 64: 'understand',\n",
       " 65: 'would',\n",
       " 66: 'That',\n",
       " 67: 'garlands',\n",
       " 68: 'through',\n",
       " 69: 'If',\n",
       " 70: 'patient',\n",
       " 71: 'very',\n",
       " 72: 'run',\n",
       " 73: 'idea',\n",
       " 74: 'led',\n",
       " 75: 'stay',\n",
       " 76: 'white',\n",
       " 77: 'height',\n",
       " 78: 'tie',\n",
       " 79: 'so',\n",
       " 80: 'doesn',\n",
       " 81: 'terribly',\n",
       " 82: 'unexpected',\n",
       " 83: 'flung',\n",
       " 84: 'bear',\n",
       " 85: 'hands',\n",
       " 86: 'object',\n",
       " 87: 'has',\n",
       " 88: 'took',\n",
       " 89: 'sign',\n",
       " 90: 'career',\n",
       " 91: 'suspected',\n",
       " 92: 'known',\n",
       " 93: 'resources',\n",
       " 94: 'became',\n",
       " 95: 'negatived',\n",
       " 96: 'protest',\n",
       " 97: 'sunburn',\n",
       " 98: 'tea',\n",
       " 99: 'foreign',\n",
       " 100: 'remained',\n",
       " 101: 'called',\n",
       " 102: 'destruction',\n",
       " 103: 'life-likeness',\n",
       " 104: 'Grafton',\n",
       " 105: 'bull',\n",
       " 106: 'romantic',\n",
       " 107: 'marble',\n",
       " 108: 'good',\n",
       " 109: 'Claude',\n",
       " 110: 'stairs',\n",
       " 111: 'I',\n",
       " 112: 'full',\n",
       " 113: 'audacities',\n",
       " 114: 'pretty',\n",
       " 115: 'sitter',\n",
       " 116: 'hair',\n",
       " 117: 'upset',\n",
       " 118: 'excuse',\n",
       " 119: 'bitterness',\n",
       " 120: 'along',\n",
       " 121: 'As',\n",
       " 122: 'feather',\n",
       " 123: 'HAD',\n",
       " 124: 'Had',\n",
       " 125: 'Venetian',\n",
       " 126: 'vista',\n",
       " 127: 'axioms',\n",
       " 128: 'began',\n",
       " 129: 'leading',\n",
       " 130: 'break',\n",
       " 131: 'near',\n",
       " 132: 'persuasively',\n",
       " 133: 'being',\n",
       " 134: 'small',\n",
       " 135: 'sunburnt',\n",
       " 136: 'oh',\n",
       " 137: 'technicalities',\n",
       " 138: 'heard',\n",
       " 139: 'added',\n",
       " 140: 'shrug',\n",
       " 141: 're',\n",
       " 142: 'breathing',\n",
       " 143: 'Victor',\n",
       " 144: 'shaking',\n",
       " 145: '_',\n",
       " 146: 'sunlit',\n",
       " 147: 'didn',\n",
       " 148: 'talking',\n",
       " 149: 'leave',\n",
       " 150: 'Never',\n",
       " 151: 'none',\n",
       " 152: 'deprecatingly',\n",
       " 153: 'can',\n",
       " 154: 'just',\n",
       " 155: 'see',\n",
       " 156: 'short',\n",
       " 157: 'next',\n",
       " 158: 'ridiculous',\n",
       " 159: 'stood',\n",
       " 160: 'inevitable',\n",
       " 161: 'showy',\n",
       " 162: 'sneer',\n",
       " 163: 'expected',\n",
       " 164: 'up-stream',\n",
       " 165: 'hot-house',\n",
       " 166: 'bravura',\n",
       " 167: 'into',\n",
       " 168: 'past',\n",
       " 169: 'wants',\n",
       " 170: 'sensation',\n",
       " 171: 'Well',\n",
       " 172: 'etching',\n",
       " 173: 'monumental',\n",
       " 174: 'wife',\n",
       " 175: 'appointed',\n",
       " 176: 'admirers',\n",
       " 177: 'current',\n",
       " 178: 'satisfaction',\n",
       " 179: 'nervousness',\n",
       " 180: 'slightly',\n",
       " 181: 'corrected',\n",
       " 182: 'Thwings',\n",
       " 183: 'Russian',\n",
       " 184: 'genial',\n",
       " 185: 'sweetness',\n",
       " 186: 'passing',\n",
       " 187: 'How',\n",
       " 188: 'Florence',\n",
       " 189: 'slight',\n",
       " 190: 'transmute',\n",
       " 191: 'time',\n",
       " 192: 'oddly',\n",
       " 193: 'follow',\n",
       " 194: 'wall',\n",
       " 195: 'Strouds',\n",
       " 196: 'Then',\n",
       " 197: 'We',\n",
       " 198: 'enabled',\n",
       " 199: 'Was',\n",
       " 200: 'No',\n",
       " 201: 'no',\n",
       " 202: 'eyebrows',\n",
       " 203: 'recovering',\n",
       " 204: 'having',\n",
       " 205: 'possessed',\n",
       " 206: 'Nutley',\n",
       " 207: 'My',\n",
       " 208: 'domestic',\n",
       " 209: 'Sevres',\n",
       " 210: 'crowned',\n",
       " 211: 'dear',\n",
       " 212: 'excusing',\n",
       " 213: 'an',\n",
       " 214: 'To',\n",
       " 215: 'discovery',\n",
       " 216: 'pockets',\n",
       " 217: 'serious',\n",
       " 218: 'happen',\n",
       " 219: 'countenance',\n",
       " 220: 'cheap',\n",
       " 221: 'says',\n",
       " 222: 'shall',\n",
       " 223: 'swept',\n",
       " 224: 'by',\n",
       " 225: 'look',\n",
       " 226: 'laugh',\n",
       " 227: 'hall',\n",
       " 228: 'frame',\n",
       " 229: 'Made',\n",
       " 230: 'presenting',\n",
       " 231: 'whenever',\n",
       " 232: 'faces',\n",
       " 233: 'surface',\n",
       " 234: 'born',\n",
       " 235: 'kind',\n",
       " 236: 'take',\n",
       " 237: 'surrounded',\n",
       " 238: 'adulation',\n",
       " 239: 'brings',\n",
       " 240: 'somebody',\n",
       " 241: 'fitting',\n",
       " 242: 'own',\n",
       " 243: 'characteristic',\n",
       " 244: 'me',\n",
       " 245: 'such',\n",
       " 246: 'cried',\n",
       " 247: 'attack',\n",
       " 248: 'alive',\n",
       " 249: 'when',\n",
       " 250: 'corner',\n",
       " 251: 'apparent',\n",
       " 252: 'outline',\n",
       " 253: 'circumstance',\n",
       " 254: 'knew',\n",
       " 255: 'dashed',\n",
       " 256: 'dress-closets',\n",
       " 257: 'while',\n",
       " 258: 'longed',\n",
       " 259: ')',\n",
       " 260: 'shoulder',\n",
       " 261: 'cheeks',\n",
       " 262: 'sight',\n",
       " 263: 'money',\n",
       " 264: 'display',\n",
       " 265: 'knees',\n",
       " 266: ',',\n",
       " 267: 'beauty',\n",
       " 268: 'your',\n",
       " 269: 'Renaissance',\n",
       " 270: 'fancy',\n",
       " 271: 'cigarette',\n",
       " 272: 'fate',\n",
       " 273: 'embarrassed',\n",
       " 274: 'half',\n",
       " 275: 'underlay',\n",
       " 276: 'on',\n",
       " 277: 'paid',\n",
       " 278: 'Monte',\n",
       " 279: 'drawing-room',\n",
       " 280: 'grew',\n",
       " 281: 'nymphs',\n",
       " 282: 'thin',\n",
       " 283: 'tears',\n",
       " 284: 'robbed',\n",
       " 285: 'lingered',\n",
       " 286: 'went',\n",
       " 287: 'vases',\n",
       " 288: 'prodigious',\n",
       " 289: 'simplifications',\n",
       " 290: 'couldn',\n",
       " 291: 'taken',\n",
       " 292: 'down',\n",
       " 293: 'water-colour',\n",
       " 294: 'have',\n",
       " 295: 'drawn',\n",
       " 296: 'instinctively',\n",
       " 297: 'painting',\n",
       " 298: 'Money',\n",
       " 299: 'fashionable',\n",
       " 300: 'single',\n",
       " 301: 'leisure',\n",
       " 302: 'appeared',\n",
       " 303: 'before',\n",
       " 304: 'extracting',\n",
       " 305: 'cured',\n",
       " 306: 'be',\n",
       " 307: 'working',\n",
       " 308: 'my',\n",
       " 309: 'get',\n",
       " 310: 'balance',\n",
       " 311: 'feet',\n",
       " 312: 'ones',\n",
       " 313: 'picture',\n",
       " 314: 'amazement',\n",
       " 315: 'hour',\n",
       " 316: 'affect',\n",
       " 317: 'women',\n",
       " 318: 'atom',\n",
       " 319: 'remember',\n",
       " 320: '--',\n",
       " 321: 'other',\n",
       " 322: 'reminded',\n",
       " 323: 'latter',\n",
       " 324: 'briefly',\n",
       " 325: 'travelled',\n",
       " 326: 'without',\n",
       " 327: 'panelling',\n",
       " 328: 'reproduction',\n",
       " 329: 'room',\n",
       " 330: 'twirling',\n",
       " 331: 'problem',\n",
       " 332: 'he',\n",
       " 333: 'over',\n",
       " 334: 'tone',\n",
       " 335: 'waves',\n",
       " 336: 'work',\n",
       " 337: 'or',\n",
       " 338: 'shrugged',\n",
       " 339: 'tell',\n",
       " 340: 'tribute',\n",
       " 341: 'whom',\n",
       " 342: 'died',\n",
       " 343: 'believed',\n",
       " 344: 't',\n",
       " 345: 'wild',\n",
       " 346: 'amusing',\n",
       " 347: 'craft',\n",
       " 348: 'glad',\n",
       " 349: 'she',\n",
       " 350: 'vocation',\n",
       " 351: 'longer',\n",
       " 352: 'paint',\n",
       " 353: 'strange',\n",
       " 354: 'away',\n",
       " 355: 'In',\n",
       " 356: 'veins',\n",
       " 357: 'recreated',\n",
       " 358: 'coming',\n",
       " 359: 'silver',\n",
       " 360: 'do',\n",
       " 361: 'getting',\n",
       " 362: 'incense',\n",
       " 363: 's',\n",
       " 364: 'sugar',\n",
       " 365: 'trade',\n",
       " 366: 'seen',\n",
       " 367: 'arm-chair',\n",
       " 368: 'worth',\n",
       " 369: 'looking',\n",
       " 370: 'better',\n",
       " 371: 'd',\n",
       " 372: 'echoed',\n",
       " 373: 'splash',\n",
       " 374: 'disdain',\n",
       " 375: 'Only',\n",
       " 376: 'medium',\n",
       " 377: 'terrace',\n",
       " 378: 'most',\n",
       " 379: 'exquisite',\n",
       " 380: 'ourselves',\n",
       " 381: 'sweetly',\n",
       " 382: 'millionaire',\n",
       " 383: 'white-panelled',\n",
       " 384: 'tributes',\n",
       " 385: 'suggested',\n",
       " 386: 'woman',\n",
       " 387: 'furrowed',\n",
       " 388: 'wanted',\n",
       " 389: 'lounging',\n",
       " 390: 'there',\n",
       " 391: 'how',\n",
       " 392: 'reassurance',\n",
       " 393: 'Lord',\n",
       " 394: 'He',\n",
       " 395: 'tells',\n",
       " 396: 'toward',\n",
       " 397: '(',\n",
       " 398: 'face',\n",
       " 399: 'Poor',\n",
       " 400: 'itself',\n",
       " 401: 'used',\n",
       " 402: ';',\n",
       " 403: 'formed',\n",
       " 404: 'poor',\n",
       " 405: 'turned',\n",
       " 406: 'why',\n",
       " 407: 'fair',\n",
       " 408: 'reared',\n",
       " 409: 'silent',\n",
       " 410: 'What',\n",
       " 411: 'Once',\n",
       " 412: 'strain',\n",
       " 413: 'been',\n",
       " 414: 'glanced',\n",
       " 415: 'oak',\n",
       " 416: 'dabble',\n",
       " 417: 'discrimination',\n",
       " 418: 'rather',\n",
       " 419: 'apparently',\n",
       " 420: 'eighteenth-century',\n",
       " 421: 'tinge',\n",
       " 422: 'give',\n",
       " 423: 'heart',\n",
       " 424: 'in',\n",
       " 425: 'greatness',\n",
       " 426: 'footstep',\n",
       " 427: 'gave',\n",
       " 428: 'spaniel',\n",
       " 429: 'phrase',\n",
       " 430: 'late',\n",
       " 431: 'elbow',\n",
       " 432: 'Riviera',\n",
       " 433: 'flashed',\n",
       " 434: 'foreseen',\n",
       " 435: 'Destroyed',\n",
       " 436: 've',\n",
       " 437: 'pride',\n",
       " 438: 'saw',\n",
       " 439: 'false',\n",
       " 440: 'muddling',\n",
       " 441: 'fostered',\n",
       " 442: 'any',\n",
       " 443: 'hide',\n",
       " 444: 'handsome',\n",
       " 445: 'growing',\n",
       " 446: 'donkey',\n",
       " 447: 'about',\n",
       " 448: 'Jack',\n",
       " 449: 'almost',\n",
       " 450: 'dimmest',\n",
       " 451: 'let',\n",
       " 452: 'enjoy',\n",
       " 453: 'value',\n",
       " 454: 'naive',\n",
       " 455: 'half-mechanically',\n",
       " 456: 'glory',\n",
       " 457: 'irrevocable',\n",
       " 458: 'alone',\n",
       " 459: 'up',\n",
       " 460: 'everlasting',\n",
       " 461: 'Burlington',\n",
       " 462: 'thought',\n",
       " 463: \"'\",\n",
       " 464: 'skill',\n",
       " 465: 'send',\n",
       " 466: 'its',\n",
       " 467: 'pictures',\n",
       " 468: 'real',\n",
       " 469: 'couple',\n",
       " 470: 'strongest',\n",
       " 471: 'princely',\n",
       " 472: 'forming',\n",
       " 473: 'sketch',\n",
       " 474: 'random',\n",
       " 475: 'raised',\n",
       " 476: 'garlanded',\n",
       " 477: 'same',\n",
       " 478: 'Greek',\n",
       " 479: 'relatively',\n",
       " 480: 'rs',\n",
       " 481: 'bric-a-brac',\n",
       " 482: 'after',\n",
       " 483: 'arms',\n",
       " 484: 'liked',\n",
       " 485: 'canvas',\n",
       " 486: 'slowly',\n",
       " 487: 'language',\n",
       " 488: 'they',\n",
       " 489: 'home',\n",
       " 490: 'happened',\n",
       " 491: 'effects',\n",
       " 492: 'Begin',\n",
       " 493: 'forgotten',\n",
       " 494: 'is',\n",
       " 495: 'poised',\n",
       " 496: 'tired',\n",
       " 497: 'since',\n",
       " 498: 'resolve',\n",
       " 499: 'wonder',\n",
       " 500: 'beneath',\n",
       " 501: 'must',\n",
       " 502: 'coat',\n",
       " 503: 'suffered',\n",
       " 504: 'Or',\n",
       " 505: 'persistence',\n",
       " 506: 'exterminating',\n",
       " 507: 'disguised',\n",
       " 508: 'forward',\n",
       " 509: 'old',\n",
       " 510: 'little',\n",
       " 511: 'course',\n",
       " 512: 'Don',\n",
       " 513: 'touched',\n",
       " 514: 'simpleton',\n",
       " 515: 'the',\n",
       " 516: 'untouched',\n",
       " 517: 'gone',\n",
       " 518: 'covered',\n",
       " 519: 'Come',\n",
       " 520: 'Devonshire',\n",
       " 521: 'widow',\n",
       " 522: 'bits',\n",
       " 523: 'stroke',\n",
       " 524: 'efforts',\n",
       " 525: 'wouldn',\n",
       " 526: 'abruptly',\n",
       " 527: 'becoming',\n",
       " 528: 'friend',\n",
       " 529: 'lines',\n",
       " 530: 'advance',\n",
       " 531: 'Hang',\n",
       " 532: 'Gallery',\n",
       " 533: 'got',\n",
       " 534: 'queerly',\n",
       " 535: 'Perhaps',\n",
       " 536: 'aside',\n",
       " 537: 'public',\n",
       " 538: 'trace',\n",
       " 539: 'show',\n",
       " 540: 'cry',\n",
       " 541: 'scornful',\n",
       " 542: 'abdication',\n",
       " 543: 'laughed',\n",
       " 544: 'gesture',\n",
       " 545: 'threshold',\n",
       " 546: 'crumbled',\n",
       " 547: 'Stroud',\n",
       " 548: 'table',\n",
       " 549: 'fit',\n",
       " 550: 'accustomed',\n",
       " 551: 'lightly',\n",
       " 552: 'damask',\n",
       " 553: 'throwing',\n",
       " 554: 'man',\n",
       " 555: 'watching',\n",
       " 556: 'much',\n",
       " 557: 'divert',\n",
       " 558: 'quality',\n",
       " 559: 'failed',\n",
       " 560: 'muscles',\n",
       " 561: 'great',\n",
       " 562: 'lovely',\n",
       " 563: 'that',\n",
       " 564: 'superb',\n",
       " 565: 'you',\n",
       " 566: 'way',\n",
       " 567: 'landing',\n",
       " 568: 'straining',\n",
       " 569: 'finality',\n",
       " 570: 'mourned',\n",
       " 571: 'fingers',\n",
       " 572: 'came',\n",
       " 573: 'reflected',\n",
       " 574: 'equally',\n",
       " 575: 'curiosity',\n",
       " 576: 'yellow',\n",
       " 577: 'indifferent',\n",
       " 578: 'standing',\n",
       " 579: 'saying',\n",
       " 580: 'insensible',\n",
       " 581: 'self-confident',\n",
       " 582: 'Croft',\n",
       " 583: 'uncertain',\n",
       " 584: 'hostess',\n",
       " 585: 'moustache',\n",
       " 586: 'forced',\n",
       " 587: 'They',\n",
       " 588: 'tempting',\n",
       " 589: 'never',\n",
       " 590: 'younger',\n",
       " 591: 'repeating',\n",
       " 592: 'But',\n",
       " 593: 'tones',\n",
       " 594: 'except',\n",
       " 595: 'buying',\n",
       " 596: 'though',\n",
       " 597: 'consummate',\n",
       " 598: 'destroyed',\n",
       " 599: 'price',\n",
       " 600: 'ease',\n",
       " 601: 'She',\n",
       " 602: 'detail',\n",
       " 603: 'us',\n",
       " 604: 'Rickham',\n",
       " 605: 'swum',\n",
       " 606: 'close',\n",
       " 607: 'Suddenly',\n",
       " 608: 'vindicated',\n",
       " 609: 'fell',\n",
       " 610: 'watched',\n",
       " 611: 'out',\n",
       " 612: 'afraid',\n",
       " 613: 'window-curtains',\n",
       " 614: 'curtains',\n",
       " 615: 'existed',\n",
       " 616: 'solace',\n",
       " 617: 'hesitations',\n",
       " 618: 'nothing',\n",
       " 619: 'started',\n",
       " 620: 'pines',\n",
       " 621: 'oval',\n",
       " 622: 'surprise',\n",
       " 623: 'could',\n",
       " 624: 'count',\n",
       " 625: 'lay',\n",
       " 626: 'Hermia',\n",
       " 627: 'wondered',\n",
       " 628: 'profusion',\n",
       " 629: 'straw',\n",
       " 630: 'day',\n",
       " 631: 'central',\n",
       " 632: 'dingy',\n",
       " 633: 'last',\n",
       " 634: 'good-breeding',\n",
       " 635: 'keep',\n",
       " 636: 'effect',\n",
       " 637: 'above',\n",
       " 638: 'Now',\n",
       " 639: 'qualities',\n",
       " 640: 'quite',\n",
       " 641: 'strongly',\n",
       " 642: 'leathery',\n",
       " 643: 'Mrs',\n",
       " 644: 'constraint',\n",
       " 645: 'circulation',\n",
       " 646: 'This',\n",
       " 647: 'greatest',\n",
       " 648: 'compared',\n",
       " 649: 'inevitably',\n",
       " 650: 'fellow',\n",
       " 651: 'till',\n",
       " 652: 'sex',\n",
       " 653: 'straddling',\n",
       " 654: 'enough',\n",
       " 655: 'quickly',\n",
       " 656: 'simply',\n",
       " 657: 'myself',\n",
       " 658: 'absurdity',\n",
       " 659: 'first',\n",
       " 660: 'of',\n",
       " 661: 'delicate',\n",
       " 662: 'secret',\n",
       " 663: 'Mr',\n",
       " 664: 'lean',\n",
       " 665: 'pardonable',\n",
       " 666: 'even',\n",
       " 667: 'idling',\n",
       " 668: 'shoulders',\n",
       " 669: 'given',\n",
       " 670: 'fond',\n",
       " 671: 'square',\n",
       " 672: 'arm-chairs',\n",
       " 673: 'felt',\n",
       " 674: 'another',\n",
       " 675: 'high',\n",
       " 676: 'it',\n",
       " 677: 'years',\n",
       " 678: 'add',\n",
       " 679: ':',\n",
       " 680: 'afterward',\n",
       " 681: 'contended',\n",
       " 682: 'degree',\n",
       " 683: 'clear',\n",
       " 684: 'stopped',\n",
       " 685: 'similar',\n",
       " 686: 'mere',\n",
       " 687: 'threw',\n",
       " 688: 'at',\n",
       " 689: 'shade',\n",
       " 690: 'equanimity',\n",
       " 691: 'ever',\n",
       " 692: 'platitudes',\n",
       " 693: 'meant',\n",
       " 694: 'don',\n",
       " 695: 'diagnosis',\n",
       " 696: 'deep',\n",
       " 697: 'tottering',\n",
       " 698: 'resented',\n",
       " 699: 'Those',\n",
       " 700: 'begun',\n",
       " 701: 'basking',\n",
       " 702: 'if',\n",
       " 703: 'with',\n",
       " 704: 'Oh',\n",
       " 705: 'Ah',\n",
       " 706: 'five',\n",
       " 707: 'stopping',\n",
       " 708: 'amid',\n",
       " 709: 'every',\n",
       " 710: 'perceptible',\n",
       " 711: 'purblind',\n",
       " 712: 'Are',\n",
       " 713: 'pink',\n",
       " 714: 'balustraded',\n",
       " 715: 'congesting',\n",
       " 716: 'painted',\n",
       " 717: 'dark',\n",
       " 718: 'portrait',\n",
       " 719: 'quietly',\n",
       " 720: 'grace',\n",
       " 721: 'dissatisfied',\n",
       " 722: 'confident',\n",
       " 723: 'really',\n",
       " 724: 'unaccountable',\n",
       " 725: 'terra-cotta',\n",
       " 726: 'hung',\n",
       " 727: 'was',\n",
       " 728: 'again',\n",
       " 729: 'easy',\n",
       " 730: 'dozen',\n",
       " 731: 'back',\n",
       " 732: 'live',\n",
       " 733: 'attitude',\n",
       " 734: 'demand',\n",
       " 735: 'bespoke',\n",
       " 736: 'drew',\n",
       " 737: 'yet',\n",
       " 738: 'reason',\n",
       " 739: 'traps',\n",
       " 740: 'loss',\n",
       " 741: 'tried',\n",
       " 742: 'canvases',\n",
       " 743: 'cigars',\n",
       " 744: 'azaleas',\n",
       " 745: 'eye',\n",
       " 746: 'doing',\n",
       " 747: 'were',\n",
       " 748: 'wish',\n",
       " 749: 'spite',\n",
       " 750: 'clasping',\n",
       " 751: 'art',\n",
       " 752: 'You',\n",
       " 753: 'Jove',\n",
       " 754: 'wide',\n",
       " 755: 'charming',\n",
       " 756: 'followed',\n",
       " 757: 'frames',\n",
       " 758: 'one',\n",
       " 759: 'Be',\n",
       " 760: 'true',\n",
       " 761: 'haven',\n",
       " 762: 'Arrt',\n",
       " 763: 'florid',\n",
       " 764: 'wander',\n",
       " 765: 'blocked',\n",
       " 766: 'who',\n",
       " 767: 'conjugal',\n",
       " 768: 'lying',\n",
       " 769: 'colour',\n",
       " 770: 'hint',\n",
       " 771: 'jardiniere',\n",
       " 772: 'varnishing',\n",
       " 773: 'dropped',\n",
       " 774: 'deprecating',\n",
       " 775: 'often',\n",
       " 776: 'gradually',\n",
       " 777: 'Though',\n",
       " 778: 'mentioned',\n",
       " 779: 'Has',\n",
       " 780: 'rain',\n",
       " 781: 'what',\n",
       " 782: 'but',\n",
       " 783: 'seemed',\n",
       " 784: 'from',\n",
       " 785: 'fullest',\n",
       " 786: 'hardly',\n",
       " 787: 'under',\n",
       " 788: 'regrets',\n",
       " 789: 'Miss',\n",
       " 790: 'history',\n",
       " 791: 'lair',\n",
       " 792: 'kept',\n",
       " 793: 'usual',\n",
       " 794: 'disarming',\n",
       " 795: 'holding',\n",
       " 796: 'lose',\n",
       " 797: 'only',\n",
       " 798: 'lends',\n",
       " 799: 'said',\n",
       " 800: 'tricks',\n",
       " 801: 'fluently',\n",
       " 802: 'pleased',\n",
       " 803: 'hadn',\n",
       " 804: 'bed',\n",
       " 805: 'chucked',\n",
       " 806: 'met',\n",
       " 807: 'now',\n",
       " 808: 'looked',\n",
       " 809: 'absolute',\n",
       " 810: 'thing',\n",
       " 811: 'herself',\n",
       " 812: 'told',\n",
       " 813: 'sent',\n",
       " 814: 'lips',\n",
       " 815: 'check',\n",
       " 816: 'Chicago',\n",
       " 817: 'collapsed',\n",
       " 818: 'always',\n",
       " 819: 'few',\n",
       " 820: 'her',\n",
       " 821: 'himself',\n",
       " 822: 'faith',\n",
       " 823: 'For',\n",
       " 824: 'not',\n",
       " 825: 'caught',\n",
       " 826: 'pale',\n",
       " 827: 'good-humoured',\n",
       " 828: 'rule',\n",
       " 829: 'famille-verte',\n",
       " 830: 'endless',\n",
       " 831: 'When',\n",
       " 832: 'for',\n",
       " 833: 'still',\n",
       " 834: 'morbidly',\n",
       " 835: 'hard',\n",
       " 836: 'surprised',\n",
       " 837: 'smile',\n",
       " 838: 'modesty',\n",
       " 839: 'half-light',\n",
       " 840: 'surest',\n",
       " 841: 'twenty-four',\n",
       " 842: 'rich',\n",
       " 843: 'end',\n",
       " 844: 'pardoned',\n",
       " 845: 'Dubarry',\n",
       " 846: 'else',\n",
       " 847: 'chair',\n",
       " 848: 'hours',\n",
       " 849: 'previous',\n",
       " 850: 'academic',\n",
       " 851: 'At',\n",
       " 852: 'continued',\n",
       " 853: 'voice',\n",
       " 854: 'multiplied',\n",
       " 855: 'may',\n",
       " 856: 'And',\n",
       " 857: 'ensuing',\n",
       " 858: 'comfortable',\n",
       " 859: 'perfect',\n",
       " 860: 'attention',\n",
       " 861: 'stuff',\n",
       " 862: 'mighty',\n",
       " 863: 'His',\n",
       " 864: 'year',\n",
       " 865: 'some',\n",
       " 866: 'sensitive',\n",
       " 867: 'egregious',\n",
       " 868: 'desultory',\n",
       " 869: 'off',\n",
       " 870: 'later',\n",
       " 871: 'elegant',\n",
       " 872: 'packed',\n",
       " 873: 'On',\n",
       " 874: 'his',\n",
       " 875: 'forehead',\n",
       " 876: 'established',\n",
       " 877: 'murmur',\n",
       " 878: 'done',\n",
       " 879: 'unusual',\n",
       " 880: 'nervous',\n",
       " 881: 'A',\n",
       " 882: 'hear',\n",
       " 883: 'hand',\n",
       " 884: 'make',\n",
       " 885: 'instructive',\n",
       " 886: 'here',\n",
       " 887: 'discussion',\n",
       " 888: 'welcome',\n",
       " 889: 'days',\n",
       " 890: 'complex',\n",
       " 891: 'reflection',\n",
       " 892: 'bean-stalk',\n",
       " 893: 'balancing',\n",
       " 894: 'ago',\n",
       " 895: 'care',\n",
       " 896: 'insignificant',\n",
       " 897: 'prestidigitation',\n",
       " 898: 'underneath',\n",
       " 899: 'gray',\n",
       " 900: 'stream',\n",
       " 901: 'cards',\n",
       " 902: 'event',\n",
       " 903: 'cleverer',\n",
       " 904: 'disease',\n",
       " 905: 'terraces',\n",
       " 906: 'Carlo',\n",
       " 907: 'gloried',\n",
       " 908: 'Yes',\n",
       " 909: 'should',\n",
       " 910: 'lifted',\n",
       " 911: 'might',\n",
       " 912: 'palm-trees',\n",
       " 913: 'savour',\n",
       " 914: 'drawing-rooms',\n",
       " 915: 'mood',\n",
       " 916: 'lump',\n",
       " 917: 'lies',\n",
       " 918: 'dim',\n",
       " 919: 'Gisburns',\n",
       " 920: 'struck',\n",
       " 921: 'prove',\n",
       " 922: 'did',\n",
       " 923: 'The',\n",
       " 924: 'sitters',\n",
       " 925: 'hermit',\n",
       " 926: 'background',\n",
       " 927: 'chimney-piece',\n",
       " 928: 'because',\n",
       " 929: '!',\n",
       " 930: 'among',\n",
       " 931: 'chap',\n",
       " 932: 'furiously',\n",
       " 933: 'across',\n",
       " 934: 'question',\n",
       " 935: 'glimpse',\n",
       " 936: 'air',\n",
       " 937: 'irony',\n",
       " 938: 'predicted',\n",
       " 939: 'quote',\n",
       " 940: 'speaking-tubes',\n",
       " 941: 'to',\n",
       " 942: 'flowers',\n",
       " 943: 'amplest',\n",
       " 944: 'escape',\n",
       " 945: 'proclaiming',\n",
       " 946: 'able',\n",
       " 947: 'It',\n",
       " 948: 'set',\n",
       " 949: 'desire',\n",
       " 950: 'aesthetic',\n",
       " 951: 'straight',\n",
       " 952: 'absorbed',\n",
       " 953: 'people',\n",
       " 954: 'pastels',\n",
       " 955: 'asked',\n",
       " 956: 'Thwing',\n",
       " 957: 'pathos',\n",
       " 958: 'then',\n",
       " 959: 'timorously',\n",
       " 960: 'least',\n",
       " 961: 'neutral',\n",
       " 962: 'stammer',\n",
       " 963: 'Just',\n",
       " 964: 'point',\n",
       " 965: 'part',\n",
       " 966: 'tips',\n",
       " 967: 'word',\n",
       " 968: 'deerhound',\n",
       " 969: 'hooded',\n",
       " 970: 'idle',\n",
       " 971: 'deploring',\n",
       " 972: 'fragment',\n",
       " 973: 'eyes',\n",
       " 974: 'married',\n",
       " 975: 'husband',\n",
       " 976: 'irrelevance',\n",
       " 977: 'trouser-presses',\n",
       " 978: 'wits',\n",
       " 979: 'Gideon',\n",
       " 980: 'claimed',\n",
       " 981: 'accuse',\n",
       " 982: 'light',\n",
       " 983: 'am',\n",
       " 984: 'crossed',\n",
       " 985: 'virtuosity',\n",
       " 986: '?',\n",
       " 987: 'form',\n",
       " 988: 'ironic',\n",
       " 989: 'There',\n",
       " 990: 'deadening',\n",
       " 991: 'rest',\n",
       " 992: 'place',\n",
       " 993: 'represented',\n",
       " 994: 'velveteen',\n",
       " 995: 'By',\n",
       " 996: 'note',\n",
       " 997: 'extenuation',\n",
       " 998: 'want',\n",
       " 999: 'faded',\n",
       " ...}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Tokenizer:\n",
    "    def __init__(self, vocab):\n",
    "        self.vocab = vocab\n",
    "        self.reverse_vocab = {v: k for k, v in vocab.items()}\n",
    "        \n",
    "    def encode(self, text):\n",
    "        result = [self.reverse_vocab[char] for char in text.split()]\n",
    "        return result\n",
    "    \n",
    "    def decode(self, text):\n",
    "        result = [self.vocab[char] for char in text]\n",
    "        return result\n",
    "\n",
    "tokenizer = Tokenizer(vocab)\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = tokenizer.encode(\"this is me\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['this', 'is', 'me']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(input_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing gpt-2 tokenizer: byte pair tokenization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[13306, 88]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(\"Goldy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Gold'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode([13306])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50257"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.n_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(50257, 30)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create embedding\n",
    "from torch import nn\n",
    "import torch as th\n",
    "embedding = nn.Embedding(50257, 30)\n",
    "embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[31373, 995, 314, 716, 21970]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"hello world I am david\"\n",
    "input_ids = tokenizer.encode(text)\n",
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids.append(50257)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index out of range in self",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[58], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mth\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/genai/lib/python3.9/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/genai/lib/python3.9/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/genai/lib/python3.9/site-packages/torch/nn/modules/sparse.py:163\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 163\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/genai/lib/python3.9/site-packages/torch/nn/functional.py:2237\u001b[0m, in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2231\u001b[0m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[1;32m   2232\u001b[0m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n\u001b[1;32m   2233\u001b[0m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[1;32m   2234\u001b[0m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[1;32m   2235\u001b[0m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[1;32m   2236\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[0;32m-> 2237\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mIndexError\u001b[0m: index out of range in self"
     ]
    }
   ],
   "source": [
    "embedding(th.tensor(input_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50257"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids.pop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0259, -0.5521, -0.5025, -0.3852, -1.4487,  1.4313,  0.2164,  2.5713,\n",
       "         -2.0453, -2.7857,  0.3548,  0.3638,  0.7200,  0.0764,  0.5517, -1.1394,\n",
       "          1.0832,  0.4797,  0.8990,  0.6999,  0.4831,  0.9679,  0.3531,  1.1215,\n",
       "         -1.8228, -0.7453, -1.4307,  0.2551,  0.9244, -0.8466],\n",
       "        [-1.1311, -0.6478,  0.2392, -1.4520, -0.9225,  0.2910,  0.2690,  0.6221,\n",
       "          0.1687, -0.1037,  0.9916, -0.8624, -0.3141,  0.4049, -2.1015, -0.5437,\n",
       "         -0.5810, -1.0365,  1.5048, -0.2985, -0.2319, -1.8894, -0.4477, -0.7516,\n",
       "         -0.2900, -0.5333, -1.0394,  0.9508,  0.4055,  0.6297],\n",
       "        [-0.8966, -1.0196,  1.9796, -0.2025, -0.9479, -0.3666, -0.6847, -0.6036,\n",
       "          0.2575,  0.9518, -0.5309,  0.0287,  0.0978, -0.5788,  0.7436,  0.5281,\n",
       "          0.3474, -0.9728, -0.3496, -0.9444, -0.3704,  0.5735,  0.5776, -1.0375,\n",
       "          0.7985, -0.7299,  0.2381,  0.3774, -1.9297, -1.9548],\n",
       "        [-1.6444,  0.3790, -1.5907, -1.7007, -0.1432,  0.4124,  1.0695, -0.1098,\n",
       "         -0.2047, -1.6469,  0.9994, -1.2325, -0.4165,  1.0747,  2.6395,  0.7188,\n",
       "          0.7279,  0.1379,  0.2206,  1.0534,  1.3833,  0.1295, -1.3197, -1.7050,\n",
       "          1.4681,  0.3209, -0.1799, -1.2572, -0.9839, -0.1079],\n",
       "        [-2.9868, -0.7347,  0.0439,  0.4743, -1.5111, -0.1224, -0.7335,  0.3535,\n",
       "          1.9479, -0.6869, -0.1693, -0.0510, -1.1536, -1.7783,  1.1526, -0.8154,\n",
       "          0.6643,  2.4595, -1.6353,  0.3273, -1.6792,  0.2334,  1.5495,  1.4622,\n",
       "         -0.1462, -0.6425, -0.4517, -0.2330, -0.5004, -0.1676]],\n",
       "       grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding(th.tensor(input_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 2.4606,  0.6403,  1.4206,  ...,  1.8374,  0.6385, -0.8951],\n",
       "        [-1.6925, -0.2427, -0.5589,  ..., -0.5965,  0.5449,  2.3124],\n",
       "        [-1.4291,  1.3848, -0.1998,  ..., -0.8891,  0.6038, -0.6890],\n",
       "        ...,\n",
       "        [ 0.1949, -0.5486,  1.8007,  ..., -1.2415, -1.2682, -0.0598],\n",
       "        [ 1.6684,  1.0297, -1.8269,  ...,  0.3577,  0.2386,  1.1856],\n",
       "        [ 1.9408,  0.7011, -1.3596,  ..., -1.1146, -0.2969,  1.8117]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"The cat sat on the mat and jumped over the moon\"\n",
    "input_ids = tokenizer.encode(sentence)\n",
    "input_embedding = embedding(th.tensor(input_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([11, 30])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([11, 11]),\n",
       " tensor([[ 27.0889,  -0.7738,  -2.1060,  -1.0440,  -4.9437,   1.7081,  -9.0385,\n",
       "           -8.6069,   2.0684,  -4.9437,   1.1981],\n",
       "         [ -0.7738,  23.0050,  -0.4378,   6.3445,  -4.0576,   1.0195,   0.6002,\n",
       "            3.7368,   8.4872,  -4.0576,  -6.4198],\n",
       "         [ -2.1060,  -0.4378,  29.5684,   4.5297,  -0.4493,   5.0289, -12.9330,\n",
       "            5.0130,   2.0453,  -0.4493,   0.0544],\n",
       "         [ -1.0440,   6.3445,   4.5297,  35.4474,   0.6730,  16.7418,  -1.0880,\n",
       "            4.8576,   9.8855,   0.6730,  -4.3427],\n",
       "         [ -4.9437,  -4.0576,  -0.4493,   0.6730,  28.4563, -12.7935,   5.5838,\n",
       "            5.2033, -13.6023,  28.4563,  -3.1565],\n",
       "         [  1.7081,   1.0195,   5.0289,  16.7418, -12.7935,  52.6238,  -6.9039,\n",
       "           -0.5158,   0.9026, -12.7935,  -1.7012],\n",
       "         [ -9.0385,   0.6002, -12.9330,  -1.0880,   5.5838,  -6.9039,  33.9555,\n",
       "           -0.0922,  -0.3648,   5.5838,   6.4365],\n",
       "         [ -8.6069,   3.7368,   5.0130,   4.8576,   5.2033,  -0.5158,  -0.0922,\n",
       "           33.2659, -12.6342,   5.2033,   6.0666],\n",
       "         [  2.0684,   8.4872,   2.0453,   9.8855, -13.6023,   0.9026,  -0.3648,\n",
       "          -12.6342,  39.8098, -13.6023, -11.1049],\n",
       "         [ -4.9437,  -4.0576,  -0.4493,   0.6730,  28.4563, -12.7935,   5.5838,\n",
       "            5.2033, -13.6023,  28.4563,  -3.1565],\n",
       "         [  1.1981,  -6.4198,   0.0544,  -4.3427,  -3.1565,  -1.7012,   6.4365,\n",
       "            6.0666, -11.1049,  -3.1565,  27.5841]], grad_fn=<MmBackward0>))"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_weight = input_embedding @ input_embedding.T\n",
    "attention_weight.shape, attention_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000e+00, 7.9314e-13, 2.0930e-13, 6.0535e-13, 1.2257e-14, 9.4891e-12,\n",
       "         2.0421e-16, 3.1442e-16, 1.3606e-11, 1.2257e-14, 5.6981e-12],\n",
       "        [4.7097e-11, 1.0000e+00, 6.5909e-11, 5.8138e-08, 1.7655e-12, 2.8302e-10,\n",
       "         1.8610e-10, 4.2848e-09, 4.9546e-07, 1.7655e-12, 1.6634e-13],\n",
       "        [1.7537e-14, 9.3000e-14, 1.0000e+00, 1.3361e-11, 9.1936e-14, 2.2010e-11,\n",
       "         3.4824e-19, 2.1663e-11, 1.1140e-12, 9.1936e-14, 1.5214e-13],\n",
       "        [1.4189e-16, 2.2949e-13, 3.7379e-14, 1.0000e+00, 7.9008e-16, 7.5202e-09,\n",
       "         1.3579e-16, 5.1882e-14, 7.9177e-12, 7.9008e-16, 5.2402e-18],\n",
       "        [1.5614e-15, 3.7874e-15, 1.3977e-13, 4.2938e-13, 5.0000e-01, 6.0872e-19,\n",
       "         5.8283e-11, 3.9838e-11, 2.7111e-19, 5.0000e-01, 9.3259e-15],\n",
       "        [7.7192e-23, 3.8772e-23, 2.1369e-21, 2.6099e-16, 3.8872e-29, 1.0000e+00,\n",
       "         1.4043e-26, 8.3515e-24, 3.4495e-23, 3.8872e-29, 2.5524e-24],\n",
       "        [2.1280e-19, 3.2658e-15, 4.3310e-21, 6.0369e-16, 4.7678e-13, 1.7989e-18,\n",
       "         1.0000e+00, 1.6341e-15, 1.2442e-15, 4.7678e-13, 1.1186e-12],\n",
       "        [6.5297e-19, 1.4985e-13, 5.3692e-13, 4.5966e-13, 6.4946e-13, 2.1320e-15,\n",
       "         3.2565e-15, 1.0000e+00, 1.1637e-20, 6.4946e-13, 1.5399e-12],\n",
       "        [4.0655e-17, 2.4932e-14, 3.9728e-17, 1.0093e-13, 6.3594e-24, 1.2671e-17,\n",
       "         3.5677e-18, 1.6744e-23, 1.0000e+00, 6.3594e-24, 7.7270e-23],\n",
       "        [1.5614e-15, 3.7874e-15, 1.3977e-13, 4.2938e-13, 5.0000e-01, 6.0872e-19,\n",
       "         5.8283e-11, 3.9838e-11, 2.7111e-19, 5.0000e-01, 9.3259e-15],\n",
       "        [3.4730e-12, 1.7073e-15, 1.1067e-12, 1.3626e-14, 4.4620e-14, 1.9123e-13,\n",
       "         6.5425e-10, 4.5195e-10, 1.5761e-17, 4.4620e-14, 1.0000e+00]],\n",
       "       grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_score = th.softmax(attention_weight, dim=-1)\n",
    "attention_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([11, 30])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_context_vector = attention_score @ input_embedding\n",
    "all_context_vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "undefined.undefined.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
